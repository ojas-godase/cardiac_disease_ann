{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d18ae1c0-2e0d-4f4e-aa7c-c38e77d4ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48687925-91a7-44f3-bf0f-1a987a45958c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "4238     1   40        3.0              0         0.0     0.0   \n",
       "4239     0   39        3.0              1        30.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "4238                0             1         0    185.0  141.0   98.0  25.60   \n",
       "4239                0             0         0    196.0  133.0   86.0  20.91   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4235       84.0     86.0           0  \n",
       "4236       86.0      NaN           0  \n",
       "4237       80.0    107.0           0  \n",
       "4238       67.0     72.0           0  \n",
       "4239       85.0     80.0           0  \n",
       "\n",
       "[4240 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"framingham.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b4a476-27e0-4296-b94c-b9438a89035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4240 entries, 0 to 4239\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4240 non-null   int64  \n",
      " 1   age              4240 non-null   int64  \n",
      " 2   education        4135 non-null   float64\n",
      " 3   currentSmoker    4240 non-null   int64  \n",
      " 4   cigsPerDay       4211 non-null   float64\n",
      " 5   BPMeds           4187 non-null   float64\n",
      " 6   prevalentStroke  4240 non-null   int64  \n",
      " 7   prevalentHyp     4240 non-null   int64  \n",
      " 8   diabetes         4240 non-null   int64  \n",
      " 9   totChol          4190 non-null   float64\n",
      " 10  sysBP            4240 non-null   float64\n",
      " 11  diaBP            4240 non-null   float64\n",
      " 12  BMI              4221 non-null   float64\n",
      " 13  heartRate        4239 non-null   float64\n",
      " 14  glucose          3852 non-null   float64\n",
      " 15  TenYearCHD       4240 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 530.1 KB\n"
     ]
    }
   ],
   "source": [
    "# check for any null values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4bf8977-e242-4e63-bf3c-e9a901d95257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4135.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4211.000000</td>\n",
       "      <td>4187.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4221.000000</td>\n",
       "      <td>4239.000000</td>\n",
       "      <td>3852.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429245</td>\n",
       "      <td>49.580189</td>\n",
       "      <td>1.979444</td>\n",
       "      <td>0.494104</td>\n",
       "      <td>9.005937</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>236.699523</td>\n",
       "      <td>132.354599</td>\n",
       "      <td>82.897759</td>\n",
       "      <td>25.800801</td>\n",
       "      <td>75.878981</td>\n",
       "      <td>81.963655</td>\n",
       "      <td>0.151887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495027</td>\n",
       "      <td>8.572942</td>\n",
       "      <td>1.019791</td>\n",
       "      <td>0.500024</td>\n",
       "      <td>11.922462</td>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.158280</td>\n",
       "      <td>44.591284</td>\n",
       "      <td>22.033300</td>\n",
       "      <td>11.910394</td>\n",
       "      <td>4.079840</td>\n",
       "      <td>12.025348</td>\n",
       "      <td>23.954335</td>\n",
       "      <td>0.358953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              male          age    education  currentSmoker   cigsPerDay  \\\n",
       "count  4240.000000  4240.000000  4135.000000    4240.000000  4211.000000   \n",
       "mean      0.429245    49.580189     1.979444       0.494104     9.005937   \n",
       "std       0.495027     8.572942     1.019791       0.500024    11.922462   \n",
       "min       0.000000    32.000000     1.000000       0.000000     0.000000   \n",
       "25%       0.000000    42.000000     1.000000       0.000000     0.000000   \n",
       "50%       0.000000    49.000000     2.000000       0.000000     0.000000   \n",
       "75%       1.000000    56.000000     3.000000       1.000000    20.000000   \n",
       "max       1.000000    70.000000     4.000000       1.000000    70.000000   \n",
       "\n",
       "            BPMeds  prevalentStroke  prevalentHyp     diabetes      totChol  \\\n",
       "count  4187.000000      4240.000000   4240.000000  4240.000000  4190.000000   \n",
       "mean      0.029615         0.005896      0.310613     0.025708   236.699523   \n",
       "std       0.169544         0.076569      0.462799     0.158280    44.591284   \n",
       "min       0.000000         0.000000      0.000000     0.000000   107.000000   \n",
       "25%       0.000000         0.000000      0.000000     0.000000   206.000000   \n",
       "50%       0.000000         0.000000      0.000000     0.000000   234.000000   \n",
       "75%       0.000000         0.000000      1.000000     0.000000   263.000000   \n",
       "max       1.000000         1.000000      1.000000     1.000000   696.000000   \n",
       "\n",
       "             sysBP        diaBP          BMI    heartRate      glucose  \\\n",
       "count  4240.000000  4240.000000  4221.000000  4239.000000  3852.000000   \n",
       "mean    132.354599    82.897759    25.800801    75.878981    81.963655   \n",
       "std      22.033300    11.910394     4.079840    12.025348    23.954335   \n",
       "min      83.500000    48.000000    15.540000    44.000000    40.000000   \n",
       "25%     117.000000    75.000000    23.070000    68.000000    71.000000   \n",
       "50%     128.000000    82.000000    25.400000    75.000000    78.000000   \n",
       "75%     144.000000    90.000000    28.040000    83.000000    87.000000   \n",
       "max     295.000000   142.500000    56.800000   143.000000   394.000000   \n",
       "\n",
       "        TenYearCHD  \n",
       "count  4240.000000  \n",
       "mean      0.151887  \n",
       "std       0.358953  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc18353b-a192-4b5c-96a3-ef6a66140ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4240 entries, 0 to 4239\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   male             4240 non-null   int64  \n",
      " 1   age              4240 non-null   int64  \n",
      " 2   education        4240 non-null   float64\n",
      " 3   currentSmoker    4240 non-null   int64  \n",
      " 4   cigsPerDay       4240 non-null   float64\n",
      " 5   BPMeds           4240 non-null   float64\n",
      " 6   prevalentStroke  4240 non-null   int64  \n",
      " 7   prevalentHyp     4240 non-null   int64  \n",
      " 8   diabetes         4240 non-null   int64  \n",
      " 9   totChol          4240 non-null   float64\n",
      " 10  sysBP            4240 non-null   float64\n",
      " 11  diaBP            4240 non-null   float64\n",
      " 12  BMI              4240 non-null   float64\n",
      " 13  heartRate        4240 non-null   float64\n",
      " 14  glucose          4240 non-null   float64\n",
      " 15  TenYearCHD       4240 non-null   int64  \n",
      "dtypes: float64(9), int64(7)\n",
      "memory usage: 530.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Let's fill all the null values by their mean value \n",
    "data[\"education\"] = data[\"education\"].fillna(data[\"education\"].mean())\n",
    "data[\"cigsPerDay\"] = data[\"cigsPerDay\"].fillna(data[\"cigsPerDay\"].mean())\n",
    "data[\"BPMeds\"] = data[\"BPMeds\"].fillna(data[\"BPMeds\"].mean())\n",
    "data[\"totChol\"] = data[\"totChol\"].fillna(data[\"totChol\"].mean())\n",
    "data[\"BMI\"] = data[\"BMI\"].fillna(data[\"BMI\"].mean())\n",
    "data[\"heartRate\"] = data[\"heartRate\"].fillna(data[\"heartRate\"].mean())\n",
    "data[\"glucose\"] = data[\"glucose\"].fillna(data[\"glucose\"].mean())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55bd6900-8ee7-4092-bb3c-b716852a29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(data[[\"male\",\"age\", \"education\" , \"currentSmoker\",\"cigsPerDay\",\"BPMeds\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\",\"totChol\",\"sysBP\",\"diaBP\",\"BMI\",\"heartRate\",\"glucose\"]])\n",
    "y = np.asarray(data['TenYearCHD'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e0ed4b2-18d0-4571-b23e-1b1fc787ccaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.15311332, -1.23428297,  2.00658417, ...,  0.28725796,\n",
       "         0.34277523, -0.21742709],\n",
       "       [-0.86721746, -0.41766419,  0.02041408, ...,  0.71966845,\n",
       "         1.59043467, -0.26123092],\n",
       "       [ 1.15311332, -0.18434454, -0.97267096, ..., -0.11321311,\n",
       "        -0.07311125, -0.52405388],\n",
       "       ...,\n",
       "       [-0.86721746,  0.28229477,  0.02041408, ..., -1.06402482,\n",
       "         0.34277523,  1.09668771],\n",
       "       [ 1.15311332, -1.11762315,  1.01349912, ..., -0.04933429,\n",
       "        -0.73852962, -0.43644623],\n",
       "       [-0.86721746, -1.23428297,  1.01349912, ..., -1.20160997,\n",
       "         0.75866171, -0.08601561]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using scaler , scale the data so that it can be easily analyzed and better for gradient descent and backpropagation.\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02103636-0441-4538-930b-def391290203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in two parts as train data and test data in 80% and 20% ratio \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "        X, y, test_size = 0.3, random_state = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eba40156-c637-4ea8-997e-5b8b6144903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=3000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "model = LogisticRegression(max_iter=3000)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ce10a38-41e4-4fb3-87b4-d5c5531ba4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "626868aa-72fa-4133-841f-057892b6bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8553459119496856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1252\n",
      "           1       0.06      0.60      0.12        20\n",
      "\n",
      "    accuracy                           0.86      1272\n",
      "   macro avg       0.53      0.73      0.52      1272\n",
      "weighted avg       0.98      0.86      0.91      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for the accuracy \n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b6652a5-eef3-4018-87ff-fc8bebf6f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The details for confusion matrix is =\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      1084\n",
      "           1       0.60      0.06      0.12       188\n",
      "\n",
      "    accuracy                           0.86      1272\n",
      "   macro avg       0.73      0.53      0.52      1272\n",
      "weighted avg       0.82      0.86      0.80      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix = pd.DataFrame(data = cm, \n",
    "                           columns = ['Predicted:0', 'Predicted:1'], \n",
    "                           index =['Actual:0', 'Actual:1'])\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = \"Greens\")\n",
    "\n",
    "plt.show()\n",
    "print('The details for confusion matrix is =')\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a54b59-2043-4517-babe-25efc64da21e",
   "metadata": {},
   "source": [
    "The above model which uses a logistic regression model has around 85-86% accuracy. So this model is pretty accurate to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557914c-f6d6-4917-a4a0-cc48cf863ca1",
   "metadata": {},
   "source": [
    "Let's try and implement SVM model and check for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3375a694-35d0-49cb-87c5-8ccf5bbe4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92      1270\n",
      "           1       0.01      0.50      0.01         2\n",
      "\n",
      "    accuracy                           0.85      1272\n",
      "   macro avg       0.50      0.68      0.47      1272\n",
      "weighted avg       1.00      0.85      0.92      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "# Trained the model\n",
    "svm.fit(X_train, y_train)\n",
    "predict_y = svm.predict(X_test)\n",
    "print(classification_report(predict_y,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8e983-c436-4865-8d37-e49d05be5126",
   "metadata": {},
   "source": [
    "This SVM model also has 85% accuracy same as logistic regression. So both models can be used for making accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7b61a-743d-4908-a184-448af85186e9",
   "metadata": {},
   "source": [
    "Both the models have high accuracy but the f1-score in predicting 1 is very low meaning that both the models are not accurate in predicting the patients who have cardiac disease. However in predicting the patients who do not have cardiac disease, both models are almost 100% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec4afd-c61f-4727-a5ed-70d115726cbb",
   "metadata": {},
   "source": [
    "Let's implement and check accuracy by using Random Forest Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b0d5d18-7448-431b-a129-06182ff1b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490566037735849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      1252\n",
      "           1       0.04      0.40      0.08        20\n",
      "\n",
      "    accuracy                           0.85      1272\n",
      "   macro avg       0.52      0.63      0.50      1272\n",
      "weighted avg       0.97      0.85      0.90      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 500)  \n",
    " \n",
    "rfc.fit(X_train, y_train)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319bc3d-6f78-4745-a5d2-2d0703c60ba7",
   "metadata": {},
   "source": [
    "Random Forest Classifier also shows around the same results meaning that there is not any significant difference between the accuracy of these three models. And maybe using Logistic Regression for this problem might be a better choice to get more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c867509-5040-4698-8137-52c490cb26cf",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6e4560e-236b-4775-b91f-789f49fb1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout layer is used to avoid overfitting the model. It drops off half of the neurons i.e. set their values to zero.\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.5))\n",
    "ann.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.5))\n",
    "ann.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9948efde-29c3-4cf5-8193-4966398b5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.7148 - loss: 14.1845 - val_accuracy: 0.8367 - val_loss: 4.2123\n",
      "Epoch 2/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7411 - loss: 5.2924 - val_accuracy: 0.8283 - val_loss: 0.5756\n",
      "Epoch 3/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7015 - loss: 2.6227 - val_accuracy: 0.8367 - val_loss: 0.6844\n",
      "Epoch 4/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7444 - loss: 1.2904 - val_accuracy: 0.8367 - val_loss: 0.6710\n",
      "Epoch 5/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7860 - loss: 0.9206 - val_accuracy: 0.8367 - val_loss: 0.6377\n",
      "Epoch 6/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8004 - loss: 0.7774 - val_accuracy: 0.8384 - val_loss: 0.6120\n",
      "Epoch 7/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.7859 - loss: 0.7341 - val_accuracy: 0.8384 - val_loss: 0.5924\n",
      "Epoch 8/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.8120 - loss: 0.6836 - val_accuracy: 0.8384 - val_loss: 0.5708\n",
      "Epoch 9/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.8138 - loss: 0.6207 - val_accuracy: 0.8384 - val_loss: 0.5418\n",
      "Epoch 10/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8140 - loss: 0.5863 - val_accuracy: 0.8384 - val_loss: 0.5360\n",
      "Epoch 11/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8265 - loss: 0.5470 - val_accuracy: 0.8367 - val_loss: 0.5062\n",
      "Epoch 12/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.8240 - loss: 0.5631 - val_accuracy: 0.8367 - val_loss: 0.5033\n",
      "Epoch 13/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8305 - loss: 0.5368 - val_accuracy: 0.8367 - val_loss: 0.4934\n",
      "Epoch 14/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8388 - loss: 0.5027 - val_accuracy: 0.8367 - val_loss: 0.4852\n",
      "Epoch 15/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8434 - loss: 0.5010 - val_accuracy: 0.8367 - val_loss: 0.4750\n",
      "Epoch 16/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8472 - loss: 0.4668 - val_accuracy: 0.8384 - val_loss: 0.4754\n",
      "Epoch 17/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8477 - loss: 0.4678 - val_accuracy: 0.8384 - val_loss: 0.4651\n",
      "Epoch 18/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8424 - loss: 0.4661 - val_accuracy: 0.8384 - val_loss: 0.4557\n",
      "Epoch 19/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8436 - loss: 0.4747 - val_accuracy: 0.8384 - val_loss: 0.4578\n",
      "Epoch 20/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8497 - loss: 0.4553 - val_accuracy: 0.8384 - val_loss: 0.4480\n",
      "Epoch 21/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8459 - loss: 0.4579 - val_accuracy: 0.8384 - val_loss: 0.4467\n",
      "Epoch 22/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.8586 - loss: 0.4344 - val_accuracy: 0.8384 - val_loss: 0.4461\n",
      "Epoch 23/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8382 - loss: 0.4755 - val_accuracy: 0.8384 - val_loss: 0.4426\n",
      "Epoch 24/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8471 - loss: 0.4429 - val_accuracy: 0.8384 - val_loss: 0.4399\n",
      "Epoch 25/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.8393 - loss: 0.4560 - val_accuracy: 0.8384 - val_loss: 0.4428\n",
      "Epoch 26/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.8649 - loss: 0.4060 - val_accuracy: 0.8384 - val_loss: 0.4429\n",
      "Epoch 27/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8452 - loss: 0.4477 - val_accuracy: 0.8384 - val_loss: 0.4400\n",
      "Epoch 28/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.8414 - loss: 0.4384 - val_accuracy: 0.8384 - val_loss: 0.4392\n",
      "Epoch 29/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8454 - loss: 0.4326 - val_accuracy: 0.8367 - val_loss: 0.4394\n",
      "Epoch 30/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.8485 - loss: 0.4486 - val_accuracy: 0.8367 - val_loss: 0.4397\n",
      "Epoch 31/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8430 - loss: 0.4386 - val_accuracy: 0.8367 - val_loss: 0.4397\n",
      "Epoch 32/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8549 - loss: 0.4249 - val_accuracy: 0.8367 - val_loss: 0.4399\n",
      "Epoch 33/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8446 - loss: 0.4468 - val_accuracy: 0.8367 - val_loss: 0.4407\n",
      "Epoch 34/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8588 - loss: 0.4152 - val_accuracy: 0.8367 - val_loss: 0.4423\n",
      "Epoch 35/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8352 - loss: 0.4471 - val_accuracy: 0.8367 - val_loss: 0.4387\n",
      "Epoch 36/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.8403 - loss: 0.4514 - val_accuracy: 0.8367 - val_loss: 0.4411\n",
      "Epoch 37/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8493 - loss: 0.4258 - val_accuracy: 0.8367 - val_loss: 0.4410\n",
      "Epoch 38/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8478 - loss: 0.4309 - val_accuracy: 0.8367 - val_loss: 0.4401\n",
      "Epoch 39/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8413 - loss: 0.4416 - val_accuracy: 0.8367 - val_loss: 0.4406\n",
      "Epoch 40/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8578 - loss: 0.4108 - val_accuracy: 0.8367 - val_loss: 0.4400\n",
      "Epoch 41/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8458 - loss: 0.4310 - val_accuracy: 0.8367 - val_loss: 0.4406\n",
      "Epoch 42/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8520 - loss: 0.4212 - val_accuracy: 0.8367 - val_loss: 0.4410\n",
      "Epoch 43/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8499 - loss: 0.4254 - val_accuracy: 0.8367 - val_loss: 0.4400\n",
      "Epoch 44/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8444 - loss: 0.4364 - val_accuracy: 0.8367 - val_loss: 0.4401\n",
      "Epoch 45/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8593 - loss: 0.4060 - val_accuracy: 0.8367 - val_loss: 0.4404\n",
      "Epoch 46/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8434 - loss: 0.4386 - val_accuracy: 0.8367 - val_loss: 0.4401\n",
      "Epoch 47/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8451 - loss: 0.4293 - val_accuracy: 0.8367 - val_loss: 0.4404\n",
      "Epoch 48/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8515 - loss: 0.4206 - val_accuracy: 0.8367 - val_loss: 0.4392\n",
      "Epoch 49/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8442 - loss: 0.4332 - val_accuracy: 0.8384 - val_loss: 0.4391\n",
      "Epoch 50/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8480 - loss: 0.4242 - val_accuracy: 0.8367 - val_loss: 0.4392\n",
      "Epoch 51/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8597 - loss: 0.4058 - val_accuracy: 0.8367 - val_loss: 0.4375\n",
      "Epoch 52/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.8508 - loss: 0.4233 - val_accuracy: 0.8384 - val_loss: 0.4380\n",
      "Epoch 53/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8460 - loss: 0.4251 - val_accuracy: 0.8384 - val_loss: 0.4379\n",
      "Epoch 54/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8540 - loss: 0.4163 - val_accuracy: 0.8384 - val_loss: 0.4407\n",
      "Epoch 55/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8503 - loss: 0.4253 - val_accuracy: 0.8384 - val_loss: 0.4407\n",
      "Epoch 56/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.8490 - loss: 0.4201 - val_accuracy: 0.8384 - val_loss: 0.4392\n",
      "Epoch 57/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8553 - loss: 0.4125 - val_accuracy: 0.8384 - val_loss: 0.4395\n",
      "Epoch 58/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8588 - loss: 0.4056 - val_accuracy: 0.8384 - val_loss: 0.4398\n",
      "Epoch 59/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.8324 - loss: 0.4467 - val_accuracy: 0.8367 - val_loss: 0.4394\n",
      "Epoch 60/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8581 - loss: 0.4060 - val_accuracy: 0.8384 - val_loss: 0.4396\n",
      "Epoch 61/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8440 - loss: 0.4295 - val_accuracy: 0.8367 - val_loss: 0.4392\n",
      "Epoch 62/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.8383 - loss: 0.4378 - val_accuracy: 0.8384 - val_loss: 0.4383\n",
      "Epoch 63/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.8522 - loss: 0.4173 - val_accuracy: 0.8384 - val_loss: 0.4395\n",
      "Epoch 64/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.8457 - loss: 0.4288 - val_accuracy: 0.8384 - val_loss: 0.4397\n",
      "Epoch 65/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8556 - loss: 0.4113 - val_accuracy: 0.8384 - val_loss: 0.4391\n",
      "Epoch 66/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8433 - loss: 0.4290 - val_accuracy: 0.8384 - val_loss: 0.4390\n",
      "Epoch 67/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8573 - loss: 0.4065 - val_accuracy: 0.8384 - val_loss: 0.4381\n",
      "Epoch 68/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.8490 - loss: 0.4165 - val_accuracy: 0.8384 - val_loss: 0.4373\n",
      "Epoch 69/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8623 - loss: 0.3978 - val_accuracy: 0.8384 - val_loss: 0.4363\n",
      "Epoch 70/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8408 - loss: 0.4366 - val_accuracy: 0.8384 - val_loss: 0.4353\n",
      "Epoch 71/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8370 - loss: 0.4400 - val_accuracy: 0.8384 - val_loss: 0.4357\n",
      "Epoch 72/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.8485 - loss: 0.4220 - val_accuracy: 0.8384 - val_loss: 0.4369\n",
      "Epoch 73/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.8602 - loss: 0.4032 - val_accuracy: 0.8384 - val_loss: 0.4362\n",
      "Epoch 74/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8500 - loss: 0.4200 - val_accuracy: 0.8384 - val_loss: 0.4362\n",
      "Epoch 75/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.8532 - loss: 0.4143 - val_accuracy: 0.8384 - val_loss: 0.4319\n",
      "Epoch 76/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8565 - loss: 0.4061 - val_accuracy: 0.8384 - val_loss: 0.4319\n",
      "Epoch 77/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8450 - loss: 0.4225 - val_accuracy: 0.8384 - val_loss: 0.4371\n",
      "Epoch 78/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.8536 - loss: 0.4123 - val_accuracy: 0.8384 - val_loss: 0.4337\n",
      "Epoch 79/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8423 - loss: 0.4313 - val_accuracy: 0.8384 - val_loss: 0.4332\n",
      "Epoch 80/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8473 - loss: 0.4229 - val_accuracy: 0.8384 - val_loss: 0.4310\n",
      "Epoch 81/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8574 - loss: 0.4081 - val_accuracy: 0.8384 - val_loss: 0.4335\n",
      "Epoch 82/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8445 - loss: 0.4294 - val_accuracy: 0.8367 - val_loss: 0.4349\n",
      "Epoch 83/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - accuracy: 0.8406 - loss: 0.4338 - val_accuracy: 0.8367 - val_loss: 0.4388\n",
      "Epoch 84/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.8462 - loss: 0.4249 - val_accuracy: 0.8367 - val_loss: 0.4358\n",
      "Epoch 85/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.8454 - loss: 0.4257 - val_accuracy: 0.8367 - val_loss: 0.4335\n",
      "Epoch 86/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.8522 - loss: 0.4154 - val_accuracy: 0.8367 - val_loss: 0.4340\n",
      "Epoch 87/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - accuracy: 0.8420 - loss: 0.4276 - val_accuracy: 0.8367 - val_loss: 0.4349\n",
      "Epoch 88/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.8594 - loss: 0.4068 - val_accuracy: 0.8367 - val_loss: 0.4360\n",
      "Epoch 89/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - accuracy: 0.8434 - loss: 0.4285 - val_accuracy: 0.8384 - val_loss: 0.4325\n",
      "Epoch 90/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.8629 - loss: 0.3961 - val_accuracy: 0.8367 - val_loss: 0.4335\n",
      "Epoch 91/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.8515 - loss: 0.4115 - val_accuracy: 0.8367 - val_loss: 0.4299\n",
      "Epoch 92/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.8404 - loss: 0.4320 - val_accuracy: 0.8367 - val_loss: 0.4334\n",
      "Epoch 93/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8373 - loss: 0.4326 - val_accuracy: 0.8367 - val_loss: 0.4339\n",
      "Epoch 94/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.8604 - loss: 0.4000 - val_accuracy: 0.8384 - val_loss: 0.4303\n",
      "Epoch 95/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.8429 - loss: 0.4271 - val_accuracy: 0.8367 - val_loss: 0.4300\n",
      "Epoch 96/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - accuracy: 0.8509 - loss: 0.4169 - val_accuracy: 0.8367 - val_loss: 0.4311\n",
      "Epoch 97/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.8549 - loss: 0.4046 - val_accuracy: 0.8367 - val_loss: 0.4262\n",
      "Epoch 98/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8518 - loss: 0.4036 - val_accuracy: 0.8367 - val_loss: 0.4286\n",
      "Epoch 99/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.8570 - loss: 0.3979 - val_accuracy: 0.8367 - val_loss: 0.4282\n",
      "Epoch 100/100\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.8537 - loss: 0.4090 - val_accuracy: 0.8367 - val_loss: 0.4329\n"
     ]
    }
   ],
   "source": [
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = ann.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c826fe3-6a26-4919-8613-4ff7e15b4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,413</span> (36.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,413\u001b[0m (36.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> (12.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,137\u001b[0m (12.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,276</span> (24.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,276\u001b[0m (24.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e339ce4f-7b6b-49b9-b1ae-b66e50386a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step - accuracy: 0.8368 - loss: 0.4392\n",
      "Test Accuracy: 85.14%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = ann.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92da07-c882-4500-82dd-8f77834a0c48",
   "metadata": {},
   "source": [
    "### The artificial neural network (ANN) also gives about the same accuracy of 85-86% as all the other models that we have implemented above. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
